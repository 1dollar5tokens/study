We have 5 storage options
    persistent storage  
    google cloud storage buckets
    google cloud spanner
    google cloud sql
    google cloud bigtable

PERSISTENT STORAGE
    Persistent storage consist of persistent disks that are durable network storage devices that are mapped to your instance. like virtual hard drives (ssd hdd). They can be resized for more storage

    they are independent of instances(vm)
        data stays on the disk even if you delete the vm it will stay on the disk unless you delete the disk also.
    The data is redundant and optimized for performance
    
    Compute engine is the service the supplies the vm with os
        local and durable storage options
        predefined machine types with specific amounts of vCPU and memory
        custom machine types the allow users to tailor their infrastructure to their workload
        integration with google cloud tech. such as Cloud Storage, App Engine, and Big Query

    Vm's is a computer within a computer that allows users to run diff OS and software on a single physical computer. 
        memory
        network
        CPU
        a hypervisor that manages the resources to ensure that each VM operates efficiently
    
    The compute engine, by default, gets deployed with a disk and contains a operating system(os) 
    You can add more disks if you need them
    Disks are can only exist in only one zone in a region and doesnt expand to multiple zones or   regions

    The vm writes data to the disks 3 times in parallel  to achieve a high rate of redundancy
        consider one persistent disk per partition instead of having multiple partitions on a single persistent disk.  For additional partitions, add additional persistent disks

    IOPS - input/output per second

    if the vm needs high IOPS then consider SSD (solid state drive)

    You can add addition disks during the creation of the vm through click ops

    You can take snapshots of the disk even if the vm is running
    
    all data is encrypted by the compute engine before it travels outside the vm and is written on the persistent disk.
        each persistent disk is encrypted either by the system defined or customer supplied keys.  Once you delete a persistent disk, Google discards its cipher keys and that data is irretrievable.
    max size of disk 64tb
    most vm's are max 64tb of disk storage space and max of 16 attached disks.
    custom vm's with less than 3.75gb of memory are limited to 3tb of total persistent disk space and a max of 4 attached disks.
    remember that the total persistent disk space of vm's includes te size of the root disk.

            attaching more than 16 disks is available in the beta feature where you can go up to 128 attached persistent disks for perdefined machine types

    another option in persistent disks is the aility to use LOCAL SSDs that are physically attached to the server that hosts the vm.  It gives you disks with higher throughput and lower latency than the standard or ssd(network based) persistent disks
    LOCAL SSDs connect through both SCSI(small computer system interface(plugs)) AND NVMe(non-volatile memory express interface(connects ssd to CPUs or servers using the PCI express(PCIe) bus)) interfaces, using a LOCAL SSD also does not count towards your network egress bandwidth cap

    The catch is that it only last as long as the vm is up and running.  
    Data remains on the local ssd if you reboot the vm or if you live migrate the vm.
        During a live migration, all data from the local ssd is copied to the vm itself and you will notice a performance decrease.  If the instance is stopped or deleted, all data is lost

    Local SSDs need to be manually stripped into a single logical volume to achieve the best performance.
    Each local SSD disk is 375gb in size and you can attach up to 8 local SSD disks to give you a total of 3tb of storage space per vm


GOOGLE CLOUD STORAGE BUCKET

    For apps that do not have low latency requirements(like first person shooters), GCS Buckets are the answer. Buckets form and object(pics files etc.) storage system that offers a very flexible, reliable, and scalable storage option for a compute engine vm.  Buckets also make it possible to share vm data across multiple vms and zones.  You can use buckets for your on premise vms as well as other cloud service providers.

    The performance is depends on the location of the bucket relative to the vm and the storage class of the bucket you are using.
        There are 4 classes. 
            multi-regional
            regional
            nearline
            coldline
        While all storage classes offer the same throughput and low latency, they differ primarily in their availability, minimum storage durations and pricing.

            To use a cloud storage bucket in an instance, you need to use the google cloud storage FILESYSTEM IN USERSPACE(FUSE) tool, which is an open source adapter for mounting cloud storage buckets. the mounted bucket behaves as a persistent disk and has a higher latency.

        Multi-regional
            is a geo-redundant storage that is appropriate for frequently accessed data.  This ensures that cloud storage will store the data in at least two separate geographical locations.  Cloud makes sure that as soon as you upload the data that it is stored in two different places. It offers a 99.9% availability SLA(Service Level Agreement). Note that multi-regional storage is in select locations.  cost the most of the 4 classes

        Regional
            this is for storing data in the same region and doesnt offer redundancy.  Having data stored within a region gives you better performance.  Regional storage offers a 99.90 SLA.

        Nearline
            This for data that will be rarely used, once a month or so. 99.00 SLA and carries a data retrieval costs along with a 30-day minimus storage duration.

        Coldline
            Is for very rarely accessed data such as archives and archival backups. lowest cost. 99.0 SLA availability and a data retrieval costs along with a 90-day minimum storage duration.

                If no class is selected then it defaults to Multi-regional if in a multi-regional region.  If in just a Regional then the standard with be regional

        Creating a bucket 
            go to storage, create a bucket, name it with an unique name has to be different than everyone else. choose a class.
            You can transfer data from amazon s3 vm or from any other http/https vm or third party buckets in to google storage buckets. this is ideal for data less than 20TB in size

            to transfer select transfer, select a source, and which bucket you want.

            for buckets with 20plus TB a transfer appliance is recommended that can securely migrate data from one bucket to another. currently the appliance is provided on a per-request basis.  there is a form for it in gcp.  

GOOGLE CLOUD SPANNER

    




    





    